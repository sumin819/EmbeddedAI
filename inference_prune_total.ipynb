{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PARK\\anaconda3\\envs\\eai\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from torchinfo import torchinfo\n",
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskClassifier, self).__init__()\n",
    "        \n",
    "        # Feature Extraction - 더 얕은 구조로 변경\n",
    "        self.features = nn.Sequential(\n",
    "            # First Block\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Second Block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Third Block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        \n",
    "        # Classifier - 더 단순한 구조로 변경\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskClassifier30(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskClassifier30, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # First Block: 3 -> 22\n",
    "            nn.Conv2d(3, 22, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(22),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Second Block: 22 -> 44 (not 45)\n",
    "            nn.Conv2d(22, 44, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(44),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Third Block: 44 -> 89 (not 90)\n",
    "            nn.Conv2d(44, 89, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(89),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(89, 2)  # 89 features, not 90\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class MaskClassifier50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskClassifier50, self).__init__()\n",
    "        \n",
    "        # 50% 프루닝된 구조\n",
    "        self.features = nn.Sequential(\n",
    "            # First Block\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # 32 * 0.5 = 16\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Second Block\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # 64 * 0.5 = 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Third Block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 128 * 0.5 = 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class MaskClassifier70(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskClassifier70, self).__init__()\n",
    "        \n",
    "        # 저장된 모델의 정확한 구조와 일치하도록 수정\n",
    "        self.features = nn.Sequential(\n",
    "            # First Block: 3 -> 9\n",
    "            nn.Conv2d(3, 9, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Second Block: 9 -> 19\n",
    "            nn.Conv2d(9, 19, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(19),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Third Block: 19 -> 38\n",
    "            nn.Conv2d(19, 38, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(38),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(38, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 함수\n",
    "def preprocess_image(image):\n",
    "    # 이미지 크기 조정\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    \n",
    "    # BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 정규화 (ImageNet stats)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    # (H, W, C) -> (C, H, W)\n",
    "    image = image.transpose(2, 0, 1)\n",
    "    \n",
    "    # numpy -> tensor\n",
    "    image = torch.FloatTensor(image).unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드 함수\n",
    "def load_pruned_model(pruning_ratio):\n",
    "    device = torch.device('cpu')\n",
    "    \"\"\"프루닝 비율에 따라 적절한 모델을 로드하는 함수\"\"\"\n",
    "    if pruning_ratio == 0.3:\n",
    "        model = MaskClassifier30().to(device)\n",
    "        model_path = \"pruned_model_30percent.pth\"\n",
    "    elif pruning_ratio == 0.5:\n",
    "        model = MaskClassifier50().to(device)\n",
    "        model_path = \"pruned_model_50percent.pth\"\n",
    "    elif pruning_ratio == 0.7:\n",
    "        model = MaskClassifier70().to(device)\n",
    "        model_path = \"pruned_model_70percent.pth\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported pruning ratio\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_webcam(pruning_ratio):\n",
    "    device = torch.device('cpu')\n",
    "    if pruning_ratio == 30:\n",
    "        model = MaskClassifier30().to(device)\n",
    "        model_path = \"pruned_model_30percent.pth\"\n",
    "    elif pruning_ratio == 50:\n",
    "        model = MaskClassifier50().to(device)\n",
    "        model_path = \"pruned_model_50percent.pth\"\n",
    "    elif pruning_ratio == 70:\n",
    "        model = MaskClassifier70().to(device)\n",
    "        model_path = \"pruned_model_70percent.pth\"\n",
    "    else:\n",
    "        model = MaskClassifier().to(device)\n",
    "        model_path = 'mask_classifier.pth'\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # 얼굴 검출을 위한 cascade classifier 로드\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    # cascade_path = \"/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml\"  # 일반적인 Linux 설치 경로\n",
    "    # face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    dataset_classes = [\"With Mask\", \"Without Mask\"]\n",
    "\n",
    "    print(\"Press 'q' to quit.\")\n",
    "    \n",
    "    # 성능 측정을 위한 변수들\n",
    "    frame_count = 0\n",
    "    total_time = 0\n",
    "    total_inference_time = 0\n",
    "    prev_time = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    while True:\n",
    "        frame_start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 좌우 반전\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # 밝기 조정 (화면 어둡게 하기)\n",
    "        brightness_offset = 0  # 밝기를 낮출 값 (0~255)\n",
    "        frame = cv2.convertScaleAbs(frame, alpha=1, beta=-brightness_offset)\n",
    "        \n",
    "        # 얼굴 검출\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(60, 60)\n",
    "        )\n",
    "        \n",
    "        # FPS 계산\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        prev_time = current_time\n",
    "        \n",
    "        # 검출된 얼굴에 대해 마스크 분류 수행\n",
    "        for (x, y, w, h) in faces:\n",
    "            # 얼굴 영역 추출\n",
    "            face_roi = frame[max(0, y-30):min(frame.shape[0], y+h+30), \n",
    "                           max(0, x-30):min(frame.shape[1], x+w+30)]\n",
    "            \n",
    "            if face_roi.size != 0:\n",
    "                # 추론 시간 측정 시작\n",
    "                inference_start = time.time()\n",
    "                \n",
    "                # 마스크 분류\n",
    "                input_tensor = preprocess_image(face_roi).to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(input_tensor)\n",
    "                    _, pred = torch.max(output, 1)\n",
    "                \n",
    "                # 추론 시간 측정 종료\n",
    "                inference_time = time.time() - inference_start\n",
    "                total_inference_time += inference_time\n",
    "                \n",
    "                # 결과 표시\n",
    "                label = dataset_classes[pred.item()]\n",
    "                color = (0, 255, 0) if \"With\" in label else (0, 0, 255)\n",
    "                \n",
    "                # 얼굴 영역 표시\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                \n",
    "                # 라벨과 추론 시간 표시\n",
    "                cv2.putText(frame, f\"{label} ({inference_time*1000:.1f}ms)\", \n",
    "                          (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        # 프레임 처리 완료 시간 계산\n",
    "        frame_time = time.time() - frame_start_time\n",
    "        total_time += frame_time\n",
    "        frame_count += 1\n",
    "        \n",
    "        # 성능 지표 표시\n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Frame Time: {frame_time*1000:.1f}ms\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # 결과 표시\n",
    "        cv2.imshow(\"Mask Detection\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 최종 성능 통계 계산\n",
    "    avg_fps = frame_count / total_time\n",
    "    avg_frame_time = total_time / frame_count\n",
    "    avg_inference_time = total_inference_time / frame_count if frame_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\n=== Performance Statistics-Pruning {pruning_ratio}%===\")\n",
    "    print(f\"Total Frames: {frame_count}\")\n",
    "    print(f\"Average FPS: {avg_fps:.1f}\")\n",
    "    print(f\"Average Frame Time: {avg_frame_time*1000:.1f}ms\")\n",
    "    print(f\"Average Inference Time: {avg_inference_time*1000:.1f}ms\\n\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_csi_camera(pruning_ratio):\n",
    "    \"\"\"\n",
    "    Jetson Nano의 CSI 카메라를 활용한 실시간 추론 함수\n",
    "    \"\"\"\n",
    "    # 모델 로드\n",
    "    device = torch.device('cpu')\n",
    "    if pruning_ratio == 30:\n",
    "        model = MaskClassifier30().to(device)\n",
    "        model_path = \"pruned_model_30percent.pth\"\n",
    "    elif pruning_ratio == 50:\n",
    "        model = MaskClassifier50().to(device)\n",
    "        model_path = \"pruned_model_50percent.pth\"\n",
    "    elif pruning_ratio == 70:\n",
    "        model = MaskClassifier70().to(device)\n",
    "        model_path = \"pruned_model_70percent.pth\"\n",
    "    else:\n",
    "        model = MaskClassifier().to(device)\n",
    "        model_path = 'mask_classifier.pth'\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # 얼굴 검출을 위한 cascade classifier 로드\n",
    "    # face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cascade_path = \"/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml\"  # 일반적인 Linux 설치 경로\n",
    "    face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    # GStreamer 파이프라인 정의\n",
    "    gst_pipeline = (\n",
    "        \"nvarguscamerasrc ! \"\n",
    "        \"video/x-raw(memory:NVMM), width=640, height=480, format=(string)NV12, framerate=30/1 ! \"\n",
    "        \"nvvidconv flip-method=0 ! \"\n",
    "        \"video/x-raw, width=640, height=480, format=(string)BGRx ! \"\n",
    "        \"videoconvert ! \"\n",
    "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
    "    )\n",
    "\n",
    "    cap = cv2.VideoCapture(gst_pipeline, cv2.CAP_GSTREAMER)\n",
    "    if not cap.isOpened():\n",
    "        print(\"CSI 카메라를 열 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    dataset_classes = [\"With Mask\", \"Without Mask\"]\n",
    "    print(\"Press 'q' to quit.\")\n",
    "    \n",
    "    # 성능 측정을 위한 변수들\n",
    "    frame_count = 0\n",
    "    total_time = 0\n",
    "    total_inference_time = 0\n",
    "    prev_time = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    while True:\n",
    "        frame_start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"카메라 프레임을 읽을 수 없습니다.\")\n",
    "            break\n",
    "        \n",
    "        # 좌우 반전\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # 밝기 조정 (화면 어둡게 하기)\n",
    "        brightness_offset = 50  # 밝기를 낮출 값 (0~255)\n",
    "        frame = cv2.convertScaleAbs(frame, alpha=1, beta=-brightness_offset)\n",
    "        \n",
    "        # 얼굴 검출\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(60, 60)\n",
    "        )\n",
    "        \n",
    "        # FPS 계산\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        prev_time = current_time\n",
    "        \n",
    "        # 검출된 얼굴에 대해 마스크 분류 수행\n",
    "        for (x, y, w, h) in faces:\n",
    "            # 얼굴 영역 추출\n",
    "            face_roi = frame[max(0, y-30):min(frame.shape[0], y+h+30), \n",
    "                           max(0, x-30):min(frame.shape[1], x+w+30)]\n",
    "            \n",
    "            if face_roi.size != 0:\n",
    "                # 추론 시간 측정 시작\n",
    "                inference_start = time.time()\n",
    "                \n",
    "                # 마스크 분류\n",
    "                input_tensor = preprocess_image(face_roi).to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(input_tensor)\n",
    "                    _, pred = torch.max(output, 1)\n",
    "                \n",
    "                # 추론 시간 측정 종료\n",
    "                inference_time = time.time() - inference_start\n",
    "                total_inference_time += inference_time\n",
    "                \n",
    "                # 결과 표시\n",
    "                label = dataset_classes[pred.item()]\n",
    "                color = (0, 255, 0) if \"With\" in label else (0, 0, 255)\n",
    "                \n",
    "                # 얼굴 영역 표시\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                \n",
    "                # 라벨과 추론 시간 표시\n",
    "                cv2.putText(frame, f\"{label} ({inference_time*1000:.1f}ms)\", \n",
    "                          (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        # 프레임 처리 완료 시간 계산\n",
    "        frame_time = time.time() - frame_start_time\n",
    "        total_time += frame_time\n",
    "        frame_count += 1\n",
    "        \n",
    "        # 성능 지표 표시\n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Frame Time: {frame_time*1000:.1f}ms\", (10, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # 결과 표시\n",
    "        cv2.imshow(\"CSI Camera Mask Detection\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 최종 성능 통계 계산\n",
    "    avg_fps = frame_count / total_time\n",
    "    avg_frame_time = total_time / frame_count\n",
    "    avg_inference_time = total_inference_time / frame_count if frame_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\n=== Performance Statistics-Pruning {pruning_ratio}%===\")\n",
    "    print(f\"Total Frames: {frame_count}\")\n",
    "    print(f\"Average FPS: {avg_fps:.1f}\")\n",
    "    print(f\"Average Frame Time: {avg_frame_time*1000:.1f}ms\")\n",
    "    print(f\"Average Inference Time: {avg_inference_time*1000:.1f}ms\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_webcam(0)\n",
    "infer_webcam(30)\n",
    "infer_webcam(50)\n",
    "infer_webcam(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSI 카메라를 열 수 없습니다.\n",
      "CSI 카메라를 열 수 없습니다.\n",
      "CSI 카메라를 열 수 없습니다.\n",
      "CSI 카메라를 열 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "infer_csi_camera(0)\n",
    "infer_csi_camera(30)\n",
    "infer_csi_camera(50)\n",
    "infer_csi_camera(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Calculate total, trainable, zero and non-zero parameters\"\"\"\n",
    "    total_params = 0\n",
    "    trainable_params = 0\n",
    "    zero_params = 0\n",
    "    nonzero_params = 0\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        total_params += p.numel()\n",
    "        if p.requires_grad:\n",
    "            trainable_params += p.numel()\n",
    "        \n",
    "        # Count zero and non-zero parameters\n",
    "        zero_params += torch.sum(p == 0).item()\n",
    "        nonzero_params += torch.sum(p != 0).item()\n",
    "    \n",
    "    return {\n",
    "        'total': total_params,\n",
    "        'trainable': trainable_params,\n",
    "        'zero': zero_params,\n",
    "        'nonzero': nonzero_params\n",
    "    }\n",
    "def calculate_flops(model):\n",
    "    \"\"\"Calculate FLOPs considering zero parameters\"\"\"\n",
    "    input_tensor = torch.randn(1, 3, 128, 128)\n",
    "    macs, params = profile(model, inputs=(input_tensor,))\n",
    "    \n",
    "    flops = 2 * macs  # Convert MACs to FLOPs\n",
    "    \n",
    "    # 0이 아닌 파라미터의 비율 계산\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:  # weight 파라미터만 고려\n",
    "            total_params += param.numel()\n",
    "            nonzero_params += torch.sum(param != 0).item()\n",
    "    \n",
    "    # 실제 수행되는 연산량 추정\n",
    "    sparsity = 1 - (nonzero_params / total_params)\n",
    "    actual_flops = flops * (1 - sparsity)\n",
    "    \n",
    "    return {\n",
    "        'raw_flops': flops,\n",
    "        'actual_flops': actual_flops,\n",
    "        'sparsity': sparsity * 100\n",
    "    }\n",
    "\n",
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in various units\"\"\"\n",
    "    # state_dict()를 통한 실제 메모리 사용량 계산\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    \n",
    "    # 파라미터 크기 계산\n",
    "    for param in model.state_dict().values():\n",
    "        param_size += param.numel() * param.element_size()\n",
    "    \n",
    "    # 버퍼 크기 계산 (BN의 running mean/var 등)\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.numel() * buffer.element_size()\n",
    "        \n",
    "    # 총 크기 계산\n",
    "    total_size = param_size + buffer_size\n",
    "    \n",
    "    # 다양한 단위로 변환\n",
    "    size_bytes = total_size\n",
    "    size_kb = total_size / 1024\n",
    "    size_mb = size_kb / 1024\n",
    "    \n",
    "    return {\n",
    "        'bytes': size_bytes,\n",
    "        'kb': size_kb,\n",
    "        'mb': size_mb,\n",
    "        'params': sum(p.numel() for p in model.parameters()),\n",
    "        'param_size': param_size,\n",
    "        'buffer_size': buffer_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_analysis():\n",
    "    \"\"\"여러 프루닝 모델들의 분석 결과를 비교하여 출력\"\"\"\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    # 모델 불러오기\n",
    "    models = {\n",
    "        'Original Model': MaskClassifier().to(device),\n",
    "        'Pruned 30%': MaskClassifier30().to(device),\n",
    "        'Pruned 50%': MaskClassifier50().to(device),\n",
    "        'Pruned 70%': MaskClassifier70().to(device)\n",
    "    }\n",
    "    \n",
    "    # 모델 가중치 로드\n",
    "    models['Original Model'].load_state_dict(torch.load(\"mask_classifier.pth\", map_location=device))\n",
    "    models['Pruned 30%'].load_state_dict(torch.load(\"pruned_model_30percent.pth\", map_location=device))\n",
    "    models['Pruned 50%'].load_state_dict(torch.load(\"pruned_model_50percent.pth\", map_location=device))\n",
    "    models['Pruned 70%'].load_state_dict(torch.load(\"pruned_model_70percent.pth\", map_location=device))\n",
    "    \n",
    "    print(\"\\n=== Model Analysis ===\")\n",
    "    \n",
    "    # 파라미터 분석\n",
    "    print(\"\\nParameter Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Model':15} {'Total Params':>15} {'Non-zero':>15} {'Zero':>15} {'Sparsity %':>15}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        params = count_parameters(model)\n",
    "        sparsity = params['zero'] / params['total'] * 100\n",
    "        print(f\"{name:15} {params['total']:15,d} {params['nonzero']:15,d} \"\n",
    "              f\"{params['zero']:15,d} {sparsity:15.1f}\")\n",
    "    \n",
    "    # 메모리 크기 분석\n",
    "    print(\"\\nMemory Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Model':15} {'Total Size(MB)':>15} {'Param Size(MB)':>20} {'Buffer Size(MB)':>20}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        size_info = get_model_size(model)\n",
    "        print(f\"{name:15} {size_info['mb']:15.2f} \"\n",
    "              f\"{size_info['param_size']/1024/1024:20.2f} \"\n",
    "              f\"{size_info['buffer_size']/1024/1024:20.2f}\")\n",
    "    \n",
    "    # FLOPs 분석\n",
    "    print(\"\\nComputational Cost Analysis:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Model':15} {'FLOPs':>20}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        flops_info = calculate_flops(model)\n",
    "        print(f\"{name:15} {flops_info['raw_flops']:20,.0f}\")\n",
    "    \n",
    "    # 실행 시간 분석 (100회 추론 평균)\n",
    "    print(\"\\nInference Time Analysis (100 runs):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Model':15} {'Average Time (ms)':>20}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    input_tensor = torch.randn(1, 3, 128, 128).to(device)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.eval()\n",
    "        times = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(100):\n",
    "                start_time = time.time()\n",
    "                _ = model(input_tensor)\n",
    "                times.append((time.time() - start_time) * 1000)  # Convert to ms\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        print(f\"{name:15} {avg_time:20.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Analysis ===\n",
      "\n",
      "Parameter Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model              Total Params        Non-zero            Zero      Sparsity %\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Original Model           93,954          93,954               0             0.0\n",
      "Pruned 30%               45,195          45,195               0             0.0\n",
      "Pruned 50%               23,938          23,938               0             0.0\n",
      "Pruned 70%                8,556           8,556               0             0.0\n",
      "\n",
      "Memory Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model            Total Size(MB)       Param Size(MB)      Buffer Size(MB)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Original Model             0.36                 0.36                 0.00\n",
      "Pruned 30%                 0.17                 0.17                 0.00\n",
      "Pruned 50%                 0.09                 0.09                 0.00\n",
      "Pruned 70%                 0.03                 0.03                 0.00\n",
      "\n",
      "Computational Cost Analysis:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model                          FLOPs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Original Model           337,707,776\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Pruned 30%               168,113,174\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Pruned 50%                93,356,416\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Pruned 70%                36,011,236\n",
      "\n",
      "Inference Time Analysis (100 runs):\n",
      "------------------------------------------------------------\n",
      "Model              Average Time (ms)\n",
      "------------------------------------------------------------\n",
      "Original Model                 25.71\n",
      "Pruned 30%                     15.77\n",
      "Pruned 50%                     12.19\n",
      "Pruned 70%                      8.98\n"
     ]
    }
   ],
   "source": [
    "print_model_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
